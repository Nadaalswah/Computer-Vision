{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### By Nour Mohamed Raafat  , Nada Abdelfatah"
      ],
      "metadata": {
        "id": "-oIGPtRRM7Eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This script performs experiments with Convolutional Neural Networks (CNNs) on the Fashion MNIST dataset using PyTorch. It trains multiple models with different configurations and evaluates their performance on the test set. Let's break down the key components of the code:\n",
        "\n",
        "## Data Loading and Preprocessing\n",
        "\n",
        "The Fashion MNIST dataset is loaded and preprocessed using torchvision transforms. It is then split into batches and loaded into DataLoader objects for training.\n",
        "\n",
        "## Model Definition\n",
        "\n",
        "A function `build_cnn()` is defined to construct CNN models with customizable parameters such as the number of input channels, hidden layers, activation functions, pooling methods, optimizer, learning rate, and dropout probability.\n",
        "\n",
        "## Training and Evaluation\n",
        "\n",
        "A function `train_and_evaluate()` is defined to train the model and evaluate its performance on the test set. It iterates over the specified number of epochs, computes the loss, and updates the model parameters using the chosen optimizer. After training, it evaluates the model accuracy on the test set.\n",
        "\n",
        "## Experimentation\n",
        "\n",
        "The script performs two types of experiments:\n",
        "\n",
        "1. **Single Model Experiment (TRY NUM : 1):**\n",
        "   - It defines a specific configuration for a single model.\n",
        "   - The model is trained and evaluated with the given configuration.\n",
        "\n",
        "2. **Multiple Model Experiments (Configurations):**\n",
        "   - It defines multiple configurations, each representing a unique combination of activation functions, pooling methods, optimizers, learning rates, dropout probabilities, and data augmentation.\n",
        "   - For each configuration, a CNN model is built, trained, and evaluated.\n",
        "\n",
        "## Professional Overview\n",
        "\n",
        "This script demonstrates a systematic approach to experimenting with CNN architectures and hyperparameters for image classification tasks. It follows best practices by modularizing the code, providing clear documentation, and conducting experiments with multiple configurations. The use of DataLoader objects ensures efficient data loading and batching during training. Additionally, the script leverages PyTorch's built-in functionalities for defining neural networks, loss computation, and optimization. Overall, it serves as a valuable tool for researchers and practitioners in the field of deep learning.\n"
      ],
      "metadata": {
        "id": "_AYOaVHOjfJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "vSvKAkVIm0np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "ah4DENOt7WDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing Data in Fashion MNIST Dataset\n",
        "\n",
        "In machine learning, preprocessing data is often crucial for effective model training. In the provided code snippet, the Fashion MNIST dataset is loaded and normalized using PyTorch's torchvision library. Let's break down the steps involved:\n",
        "\n",
        "## Transform Definition\n",
        "\n",
        "A transform is a set of operations applied to each sample in the dataset during loading. In this case, the `transforms.Compose` function is used to create a sequence of transformations. Two transformations are applied:\n",
        "\n",
        "1. **ToTensor**: This transformation converts the input image data into a PyTorch tensor. It converts the image data from PIL format (or other formats) to a tensor, which is a multi-dimensional array suitable for processing by neural networks.\n",
        "\n",
        "2. **Normalize**: Normalization is a common preprocessing step in deep learning. It standardizes the pixel values of the input images to have a mean and standard deviation of 0.5. This helps in stabilizing the training process by bringing the input data to a similar scale.\n",
        "\n",
        "## Loading Fashion MNIST Dataset\n",
        "\n",
        "The Fashion MNIST dataset is a collection of grayscale images of clothing items belonging to 10 different categories. The `torchvision.datasets.FashionMNIST` class is used to load the dataset. Parameters such as the root directory, whether to download the dataset if not found locally, and the specified transform are provided to the constructor.\n",
        "\n",
        "## DataLoader Configuration\n",
        "\n",
        "After loading the dataset, it is split into batches using the `torch.utils.data.DataLoader` class. This class provides an iterable over the dataset, handling batching, shuffling, and multiprocessing for data loading. In this case, each batch contains 4 samples, and the data is shuffled during loading. The `num_workers` parameter specifies the number of subprocesses used for data loading.\n",
        "\n",
        "By applying these transformations and configuring the DataLoader, the Fashion MNIST dataset is prepared for training neural network models, ensuring efficient processing and improved model performance.\n"
      ],
      "metadata": {
        "id": "z3KaPR_HjplV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "UtDyZN147yJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7953bdcc-f28a-4a31-b42b-e1f60287d29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 6699465.36it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 112460.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2248719.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4586295.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model Function Explanation\n",
        "\n",
        "The provided code defines a function called `build_cnn()` which is responsible for constructing a Convolutional Neural Network (CNN) model with customizable parameters. Let's go through the details of this function:\n",
        "\n",
        "## Function Purpose\n",
        "\n",
        "The purpose of this function is to create a CNN model tailored to specific requirements such as input image properties, architecture of hidden layers, activation functions, pooling methods, optimizer choice, learning rate, and dropout probability.\n",
        "\n",
        "## Function Arguments\n",
        "\n",
        "- **in_channels**: Specifies the number of input channels, typically 1 for grayscale images.\n",
        "- **hidden_layers**: A list of tuples specifying the configuration of hidden convolutional layers. Each tuple contains the number of filters and filter size for the respective layer.\n",
        "- **activation**: Activation function to be applied to hidden layers, such as 'Sigmoid', 'Tanh', or 'ReLU'.\n",
        "- **pooling**: Pooling function to be used, either 'max' for max pooling or 'avg' for average pooling.\n",
        "- **optimizer**: Optimizer to use for training the model, including options like 'adam', 'sgd', or 'rmsprop'.\n",
        "- **lr**: Learning rate, which controls the step size during optimization.\n",
        "- **dropout_prob**: Probability for dropout regularization, with a default value of 0.\n",
        "\n",
        "## Model Construction Steps\n",
        "\n",
        "1. **Input Layer**:\n",
        "   - Adds a convolutional layer with the specified number of input channels, 32 output channels, kernel size of 3x3, and padding of 1.\n",
        "\n",
        "2. **Hidden Convolutional Layers**:\n",
        "   - Iterates through the list of hidden layers, adding convolutional layers with the specified number of filters and kernel size.\n",
        "   - Applies the specified activation function dynamically using `getattr(nn, activation)()`.\n",
        "   - Incorporates either max or average pooling based on the provided pooling function.\n",
        "\n",
        "3. **Dropout Layer**:\n",
        "   - Adds a dropout layer if the dropout probability is greater than 0.\n",
        "\n",
        "4. **Flatten Layer**:\n",
        "   - Flattens the output of convolutional layers to prepare for input to fully connected layers.\n",
        "\n",
        "5. **Fully Connected Layers**:\n",
        "   - Adds a fully connected layer with 64 neurons and applies the specified activation function.\n",
        "   - Adds the output layer with 10 neurons for classifying into 10 fashion classes.\n",
        "\n",
        "## Optimizer Selection\n",
        "\n",
        "- The function selects the optimizer based on the provided optimizer argument and initializes it with the model parameters and learning rate.\n",
        "\n",
        "## Error Handling\n",
        "\n",
        "- Raises a ValueError if an invalid optimizer is provided.\n",
        "\n",
        "This function provides a flexible and customizable way to create CNN models suited to various image classification tasks, allowing researchers and practitioners to experiment with different architectures and configurations.\n"
      ],
      "metadata": {
        "id": "dogdskw0kApi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Building"
      ],
      "metadata": {
        "id": "w4i2nGUX509a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model function with path arguments\n",
        "def build_cnn(in_channels, hidden_layers, activation, pooling, optimizer, lr, dropout_prob=0):\n",
        "  \"\"\"\n",
        "  Builds a CNN model with customizable parameters.\n",
        "\n",
        "  Args:\n",
        "      in_channels: Number of input channels (usually 1 for grayscale images).\n",
        "      hidden_layers: List of tuples specifying (number of filters, filter size) for convolutional layers.\n",
        "      activation: Activation function for hidden layers (e.g., 'Sigmoid', 'Tanh', 'ReLU').\n",
        "      pooling: Pooling function ('max' or 'avg').\n",
        "      optimizer: Optimizer (e.g., 'adam', 'sgd', 'rmsprop').\n",
        "      lr: Learning rate.\n",
        "      dropout_prob: Probability for dropout regularization (default: 0).\n",
        "\n",
        "  Returns:\n",
        "      A PyTorch CNN model.\n",
        "  \"\"\"\n",
        "\n",
        "  layers = []\n",
        "\n",
        "  # Input layer (adjust based on input image size)\n",
        "  layers.append(nn.Conv2d(in_channels, 32, kernel_size=3, padding=1))\n",
        "\n",
        "  # Add hidden convolutional layers\n",
        "  prev_channels = 32  # Initially, the number of input channels is 32\n",
        "  for filters, kernel_size in hidden_layers:\n",
        "    layers.append(nn.Conv2d(prev_channels, filters, kernel_size=kernel_size, padding=1))\n",
        "    layers.append(getattr(nn, activation)())  # Use getattr for dynamic activation selection\n",
        "\n",
        "    if pooling == 'max':\n",
        "      layers.append(nn.MaxPool2d(2, 2))  # Max pooling\n",
        "    elif pooling == 'avg':\n",
        "      layers.append(nn.AvgPool2d(2, 2))  # Average pooling\n",
        "    else:\n",
        "      raise ValueError(\"Invalid pooling function: {}\".format(pooling))\n",
        "\n",
        "    # Add dropout layer if specified\n",
        "    if dropout_prob > 0:\n",
        "      layers.append(nn.Dropout(dropout_prob))\n",
        "\n",
        "    prev_channels = filters  # Update the number of input channels for the next layer\n",
        "\n",
        "  # Flatten for fully connected layers\n",
        "  layers.append(nn.Flatten())\n",
        "\n",
        "  # Fully connected layers (adjust number of neurons as needed)\n",
        "  layers.append(nn.Linear(prev_channels * 7 * 7, 64))  # Example fully connected layer\n",
        "  layers.append(getattr(nn, activation)())  # Apply activation to fully connected layers\n",
        "\n",
        "  layers.append(nn.Linear(64, 10))  # Output layer for 10 fashion classes\n",
        "\n",
        "  model = nn.Sequential(*layers)\n",
        "\n",
        "  # Select optimizer based on argument\n",
        "  if optimizer == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  elif optimizer == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  elif optimizer == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "  else:\n",
        "    raise ValueError(\"Invalid optimizer: {}\".format(optimizer))\n",
        "\n",
        "  return model, optimizer"
      ],
      "metadata": {
        "id": "X9v1ywxtBCYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation Function Explanation\n",
        "\n",
        "The provided code defines a function called `train_and_evaluate()` which serves the purpose of training a given CNN model and evaluating its performance on a test dataset. Let's break down the details of this function:\n",
        "\n",
        "## Function Purpose\n",
        "\n",
        "This function is responsible for training a CNN model using the provided optimizer and DataLoader for training data. After training, it evaluates the trained model's accuracy on a separate test dataset.\n",
        "\n",
        "## Function Arguments\n",
        "\n",
        "- **model**: The CNN model to be trained and evaluated.\n",
        "- **optimizer**: The optimizer used for training the model.\n",
        "- **train_loader**: DataLoader containing the training data.\n",
        "- **test_loader**: DataLoader containing the test data.\n",
        "- **epochs**: Number of training epochs.\n",
        "\n",
        "## Training Loop\n",
        "\n",
        "- The function iterates through each epoch, during which it trains the model using the provided optimizer and training data.\n",
        "- Within each epoch, it iterates through batches of data from the training DataLoader (`train_loader`).\n",
        "- For each batch, it performs a forward pass through the model, calculates the loss using the specified loss function (`nn.CrossEntropyLoss()`), computes gradients, and updates the model parameters using the optimizer.\n",
        "- It also tracks the running loss for each epoch and prints the average loss every 2000 batches.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "- After completing training for all epochs, the function evaluates the model's performance on the test dataset.\n",
        "- It switches the model to evaluation mode using `model.eval()` to disable dropout and batch normalization layers.\n",
        "- Then, it iterates through batches of data from the test DataLoader (`test_loader`).\n",
        "- For each batch, it performs a forward pass through the model to obtain predictions.\n",
        "- It compares the predicted labels with the ground truth labels and calculates the total number of correct predictions.\n",
        "- Finally, it computes the accuracy of the model on the test dataset and prints the result.\n",
        "\n",
        "## Return Value\n",
        "\n",
        "The function returns the average test accuracy over all epochs, providing a measure of the model's performance.\n",
        "\n",
        "This function encapsulates the process of training and evaluating a CNN model, allowing users to easily monitor training progress and assess model accuracy on unseen data.\n"
      ],
      "metadata": {
        "id": "zwAJ2JirkLhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and evaluation function\n",
        "def train_and_evaluate(model, optimizer, train_loader, test_loader, epochs):\n",
        "  \"\"\"\n",
        "  Trains the model and evaluates performance on the test set.\n",
        "\n",
        "  Args:\n",
        "      model: The CNN model to train.\n",
        "      optimizer: The optimizer to use.\n",
        "      train_loader: DataLoader for training data.\n",
        "      test_loader: DataLoader for test data.\n",
        "      epochs: Number of training epochs.\n",
        "\n",
        "  Returns:\n",
        "      The average test accuracy over epochs.\n",
        "  \"\"\"\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "      inputs, labels = data\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if i % 2000 == 1999:\n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "        running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  # Evaluation on test set\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "  return 100 * correct / total"
      ],
      "metadata": {
        "id": "P5ZZkoajc3mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRY NUM : 1\n",
        "\n",
        "  Args:\n",
        "  <br>\n",
        "  *   in_channels:1\n",
        "      <br>\n",
        "  *   hidden_layers: [(64, 3), (64, 3)]  \n",
        "      \n",
        "  *   activation: 'ReLU'\n",
        "      <br>\n",
        "  *   pooling: 'max'\n",
        "      <br>\n",
        "  *   optimizer: 'adam'\n",
        "      <br>\n",
        "  *   lr: 0.001\n",
        "      <br>\n",
        "  *   dropout_prob: 0.5"
      ],
      "metadata": {
        "id": "DMAe2J3fdV38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for CNN model\n",
        "in_channels = 1\n",
        "hidden_layers = [(64, 3), (64, 3)]  # Example hidden layers\n",
        "activation = 'ReLU'  # Corrected activation function name\n",
        "pooling = 'max'\n",
        "optimizer = 'adam'\n",
        "lr = 0.001\n",
        "dropout_prob = 0.5\n",
        "epochs = 5\n",
        "\n",
        "# Build the CNN model\n",
        "model, optimizer = build_cnn(in_channels, hidden_layers, activation, pooling, optimizer, lr, dropout_prob)\n",
        "\n",
        "# Train and evaluate the model\n",
        "test_accuracy = train_and_evaluate(model, optimizer, trainloader, trainloader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f236a7-e51f-4565-aece-d8f3c07b1255",
        "id": "scTO0qv7eFAi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 0.763\n",
            "[1,  4000] loss: 0.558\n",
            "[1,  6000] loss: 0.505\n",
            "[1,  8000] loss: 0.476\n",
            "[1, 10000] loss: 0.476\n",
            "[1, 12000] loss: 0.451\n",
            "[1, 14000] loss: 0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,  2000] loss: 0.426\n",
            "[2,  4000] loss: 0.426\n",
            "[2,  6000] loss: 0.407\n",
            "[2,  8000] loss: 0.411\n",
            "[2, 10000] loss: 0.409\n",
            "[2, 12000] loss: 0.413\n",
            "[2, 14000] loss: 0.415\n",
            "[3,  2000] loss: 0.399\n",
            "[3,  4000] loss: 0.390\n",
            "[3,  6000] loss: 0.399\n",
            "[3,  8000] loss: 0.401\n",
            "[3, 10000] loss: 0.364\n",
            "[3, 12000] loss: 0.396\n",
            "[3, 14000] loss: 0.407\n",
            "[4,  2000] loss: 0.375\n",
            "[4,  4000] loss: 0.375\n",
            "[4,  6000] loss: 0.385\n",
            "[4,  8000] loss: 0.378\n",
            "[4, 10000] loss: 0.375\n",
            "[4, 12000] loss: 0.406\n",
            "[4, 14000] loss: 0.358\n",
            "[5,  2000] loss: 0.380\n",
            "[5,  4000] loss: 0.381\n",
            "[5,  6000] loss: 0.354\n",
            "[5,  8000] loss: 0.362\n",
            "[5, 10000] loss: 0.373\n",
            "[5, 12000] loss: 0.399\n",
            "[5, 14000] loss: 0.371\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 89 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Architectures\n",
        "## Parameters for Base CNN Model\n",
        "- Input Channels: 1 (grayscale images)\n",
        "- Hidden Layers: Two convolutional layers with 64 filters each and kernel size of 3x3\n",
        "- Epochs: 5\n",
        "\n",
        "## Configurations to Try\n",
        "We define six different configurations, each with variations in activation, pooling, optimizer, learning rate, dropout probability, and data augmentation.\n",
        "\n",
        "\n",
        "**Configuration 2:**\n",
        "   - Activation: Tanh\n",
        "   - Pooling: Max\n",
        "   - Optimizer: Adam\n",
        "   - Learning Rate: 0.001\n",
        "   - Dropout Probability: 0.5\n",
        "   - Data Augmentation: Disabled\n",
        "\n",
        "**Configuration 3:**\n",
        "   - Activation: ReLU\n",
        "   - Pooling: Average\n",
        "   - Optimizer: Adam\n",
        "   - Learning Rate: 0.01\n",
        "   - Dropout Probability: 0\n",
        "   - Data Augmentation: Enabled\n",
        "\n",
        "**Configuration 4:**\n",
        "   - Activation: ReLU\n",
        "   - Pooling: Average\n",
        "   - Optimizer: Adam\n",
        "   - Learning Rate: 0.01\n",
        "   - Dropout Probability: 0.5\n",
        "   - Data Augmentation: Disabled\n",
        "\n",
        "**Configuration 5:**\n",
        "   - Activation: ReLU\n",
        "   - Pooling: Max\n",
        "   - Optimizer: SGD\n",
        "   - Learning Rate: 0.01\n",
        "   - Dropout Probability: 0\n",
        "   - Data Augmentation: Enabled\n",
        "\n",
        "**Configuration 6:**\n",
        "   - Activation: ReLU\n",
        "   - Pooling: Max\n",
        "   - Optimizer: SGD\n",
        "   - Learning Rate: 0.01\n",
        "   - Dropout Probability: 0.5\n",
        "   - Data Augmentation: Enabled\n",
        "\n",
        "**Configuration 7:**\n",
        "   - Activation: Sigmoid\n",
        "   - Pooling: Max\n",
        "   - Optimizer: SGD\n",
        "   - Learning Rate: 0.05\n",
        "   - Dropout Probability: 0.5\n",
        "   - Data Augmentation: Enabled\n",
        "\n",
        "**Configuration 8:**\n",
        "   - Activation: Sigmoid\n",
        "   - Pooling: Max\n",
        "   - Optimizer: SGD\n",
        "   - Learning Rate: 0.05\n",
        "   - Dropout Probability: 0\n",
        "   - Data Augmentation: Enabled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uk4bJLhI3qp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for CNN model\n",
        "in_channels = 1\n",
        "hidden_layers = [(64, 3), (64, 3)]  # Example hidden layers\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "qq2Ns4XuAOfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define different configurations to try\n",
        "configurations = [\n",
        "    {'activation': 'Sigmoid', 'pooling': 'max', 'optimizer': 'adam', 'lr': 0.001, 'dropout_prob': 0.5, 'augmentation': True},\n",
        "    {'activation': 'Tanh', 'pooling': 'max', 'optimizer': 'adam', 'lr': 0.001, 'dropout_prob': 0.5, 'augmentation': False},\n",
        "    {'activation': 'ReLU', 'pooling': 'avg', 'optimizer': 'adam', 'lr': 0.01, 'dropout_prob': 0, 'augmentation': True},\n",
        "    {'activation': 'ReLU', 'pooling': 'avg', 'optimizer': 'adam', 'lr': 0.01, 'dropout_prob': 0.5, 'augmentation': False},\n",
        "    {'activation': 'ReLU', 'pooling': 'max', 'optimizer': 'sgd', 'lr': 0.01, 'dropout_prob': 0, 'augmentation': True},\n",
        "    {'activation': 'ReLU', 'pooling': 'max', 'optimizer': 'sgd', 'lr': 0.01, 'dropout_prob': 0.5, 'augmentation': True},\n",
        "]\n",
        "\n",
        "# Iterate over configurations and train models\n",
        "for idx, config in enumerate(configurations, start=1):\n",
        "    print(f\"Training Model {idx}\")\n",
        "\n",
        "    activation = config['activation']\n",
        "    pooling = config['pooling']\n",
        "    optimizer = config['optimizer']\n",
        "    lr = config['lr']\n",
        "    dropout_prob = config['dropout_prob']\n",
        "    augmentation = config['augmentation']\n",
        "\n",
        "    # Build the CNN model\n",
        "    model, optimizer = build_cnn(in_channels, hidden_layers, activation, pooling, optimizer, lr, dropout_prob)\n",
        "\n",
        "    # Data augmentation\n",
        "    if augmentation:\n",
        "        trainset_augmented = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True,\n",
        "                                                               transform=transforms.Compose([\n",
        "                                                                   transforms.RandomHorizontalFlip(),\n",
        "                                                                   transforms.RandomRotation(10),\n",
        "                                                                   transforms.ToTensor(),\n",
        "                                                                   transforms.Normalize((0.5,), (0.5,))\n",
        "                                                               ]))\n",
        "        trainloader_augmented = torch.utils.data.DataLoader(trainset_augmented, batch_size=4, shuffle=True, num_workers=2)\n",
        "        trainloader_used = trainloader_augmented\n",
        "    else:\n",
        "        trainloader_used = trainloader\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    test_accuracy = train_and_evaluate(model, optimizer, trainloader_used, trainloader, epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVQLJ9Q0MDLz",
        "outputId": "4688e7f7-4b80-4774-aa2d-f731afd27b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.092\n",
            "[1,  4000] loss: 0.727\n",
            "[1,  6000] loss: 0.632\n",
            "[1,  8000] loss: 0.575\n",
            "[1, 10000] loss: 0.562\n",
            "[1, 12000] loss: 0.545\n",
            "[1, 14000] loss: 0.507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,  2000] loss: 0.493\n",
            "[2,  4000] loss: 0.483\n",
            "[2,  6000] loss: 0.465\n",
            "[2,  8000] loss: 0.469\n",
            "[2, 10000] loss: 0.484\n",
            "[2, 12000] loss: 0.454\n",
            "[2, 14000] loss: 0.453\n",
            "[3,  2000] loss: 0.441\n",
            "[3,  4000] loss: 0.440\n",
            "[3,  6000] loss: 0.432\n",
            "[3,  8000] loss: 0.443\n",
            "[3, 10000] loss: 0.431\n",
            "[3, 12000] loss: 0.437\n",
            "[3, 14000] loss: 0.427\n",
            "[4,  2000] loss: 0.413\n",
            "[4,  4000] loss: 0.409\n",
            "[4,  6000] loss: 0.425\n",
            "[4,  8000] loss: 0.409\n",
            "[4, 10000] loss: 0.397\n",
            "[4, 12000] loss: 0.411\n",
            "[4, 14000] loss: 0.422\n",
            "[5,  2000] loss: 0.392\n",
            "[5,  4000] loss: 0.405\n",
            "[5,  6000] loss: 0.391\n",
            "[5,  8000] loss: 0.416\n",
            "[5, 10000] loss: 0.383\n",
            "[5, 12000] loss: 0.397\n",
            "[5, 14000] loss: 0.403\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 88 %\n",
            "Training Model 2\n",
            "[1,  2000] loss: 0.674\n",
            "[1,  4000] loss: 0.544\n",
            "[1,  6000] loss: 0.531\n",
            "[1,  8000] loss: 0.519\n",
            "[1, 10000] loss: 0.519\n",
            "[1, 12000] loss: 0.506\n",
            "[1, 14000] loss: 0.492\n",
            "[2,  2000] loss: 0.482\n",
            "[2,  4000] loss: 0.502\n",
            "[2,  6000] loss: 0.498\n",
            "[2,  8000] loss: 0.493\n",
            "[2, 10000] loss: 0.479\n",
            "[2, 12000] loss: 0.470\n",
            "[2, 14000] loss: 0.483\n",
            "[3,  2000] loss: 0.454\n",
            "[3,  4000] loss: 0.449\n",
            "[3,  6000] loss: 0.496\n",
            "[3,  8000] loss: 0.489\n",
            "[3, 10000] loss: 0.473\n",
            "[3, 12000] loss: 0.461\n",
            "[3, 14000] loss: 0.468\n",
            "[4,  2000] loss: 0.467\n",
            "[4,  4000] loss: 0.462\n",
            "[4,  6000] loss: 0.464\n",
            "[4,  8000] loss: 0.464\n",
            "[4, 10000] loss: 0.450\n",
            "[4, 12000] loss: 0.482\n",
            "[4, 14000] loss: 0.473\n",
            "[5,  2000] loss: 0.477\n",
            "[5,  4000] loss: 0.480\n",
            "[5,  6000] loss: 0.458\n",
            "[5,  8000] loss: 0.454\n",
            "[5, 10000] loss: 0.468\n",
            "[5, 12000] loss: 0.473\n",
            "[5, 14000] loss: 0.455\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Training Model 3\n",
            "[1,  2000] loss: 1.039\n",
            "[1,  4000] loss: 0.770\n",
            "[1,  6000] loss: 1.749\n",
            "[1,  8000] loss: 2.315\n",
            "[1, 10000] loss: 2.309\n",
            "[1, 12000] loss: 2.308\n",
            "[1, 14000] loss: 2.306\n",
            "[2,  2000] loss: 2.306\n",
            "[2,  4000] loss: 2.306\n",
            "[2,  6000] loss: 2.306\n",
            "[2,  8000] loss: 2.306\n",
            "[2, 10000] loss: 2.307\n",
            "[2, 12000] loss: 2.306\n",
            "[2, 14000] loss: 2.307\n",
            "[3,  2000] loss: 2.306\n",
            "[3,  4000] loss: 2.308\n",
            "[3,  6000] loss: 2.306\n",
            "[3,  8000] loss: 2.306\n",
            "[3, 10000] loss: 2.306\n",
            "[3, 12000] loss: 2.306\n",
            "[3, 14000] loss: 2.306\n",
            "[4,  2000] loss: 2.307\n",
            "[4,  4000] loss: 2.306\n",
            "[4,  6000] loss: 2.306\n",
            "[4,  8000] loss: 2.307\n",
            "[4, 10000] loss: 2.306\n",
            "[4, 12000] loss: 2.305\n",
            "[4, 14000] loss: 2.307\n",
            "[5,  2000] loss: 2.306\n",
            "[5,  4000] loss: 2.306\n",
            "[5,  6000] loss: 2.306\n",
            "[5,  8000] loss: 2.305\n",
            "[5, 10000] loss: 2.307\n",
            "[5, 12000] loss: 2.307\n",
            "[5, 14000] loss: 2.306\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 10 %\n",
            "Training Model 4\n",
            "[1,  2000] loss: 2.314\n",
            "[1,  4000] loss: 2.307\n",
            "[1,  6000] loss: 2.310\n",
            "[1,  8000] loss: 2.312\n",
            "[1, 10000] loss: 2.308\n",
            "[1, 12000] loss: 2.357\n",
            "[1, 14000] loss: 2.306\n",
            "[2,  2000] loss: 2.307\n",
            "[2,  4000] loss: 2.306\n",
            "[2,  6000] loss: 2.307\n",
            "[2,  8000] loss: 2.306\n",
            "[2, 10000] loss: 2.307\n",
            "[2, 12000] loss: 2.325\n",
            "[2, 14000] loss: 2.307\n",
            "[3,  2000] loss: 2.306\n",
            "[3,  4000] loss: 2.305\n",
            "[3,  6000] loss: 2.305\n",
            "[3,  8000] loss: 2.307\n",
            "[3, 10000] loss: 2.307\n",
            "[3, 12000] loss: 2.307\n",
            "[3, 14000] loss: 2.306\n",
            "[4,  2000] loss: 2.306\n",
            "[4,  4000] loss: 2.307\n",
            "[4,  6000] loss: 2.306\n",
            "[4,  8000] loss: 2.306\n",
            "[4, 10000] loss: 2.306\n",
            "[4, 12000] loss: 2.306\n",
            "[4, 14000] loss: 2.309\n",
            "[5,  2000] loss: 2.308\n",
            "[5,  4000] loss: 2.307\n",
            "[5,  6000] loss: 2.307\n",
            "[5,  8000] loss: 2.307\n",
            "[5, 10000] loss: 2.306\n",
            "[5, 12000] loss: 2.307\n",
            "[5, 14000] loss: 2.307\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 10 %\n",
            "Training Model 5\n",
            "[1,  2000] loss: 0.940\n",
            "[1,  4000] loss: 0.578\n",
            "[1,  6000] loss: 0.495\n",
            "[1,  8000] loss: 0.470\n",
            "[1, 10000] loss: 0.431\n",
            "[1, 12000] loss: 0.426\n",
            "[1, 14000] loss: 0.385\n",
            "[2,  2000] loss: 0.363\n",
            "[2,  4000] loss: 0.351\n",
            "[2,  6000] loss: 0.349\n",
            "[2,  8000] loss: 0.344\n",
            "[2, 10000] loss: 0.341\n",
            "[2, 12000] loss: 0.330\n",
            "[2, 14000] loss: 0.311\n",
            "[3,  2000] loss: 0.307\n",
            "[3,  4000] loss: 0.300\n",
            "[3,  6000] loss: 0.300\n",
            "[3,  8000] loss: 0.287\n",
            "[3, 10000] loss: 0.297\n",
            "[3, 12000] loss: 0.296\n",
            "[3, 14000] loss: 0.280\n",
            "[4,  2000] loss: 0.276\n",
            "[4,  4000] loss: 0.271\n",
            "[4,  6000] loss: 0.273\n",
            "[4,  8000] loss: 0.270\n",
            "[4, 10000] loss: 0.266\n",
            "[4, 12000] loss: 0.277\n",
            "[4, 14000] loss: 0.269\n",
            "[5,  2000] loss: 0.261\n",
            "[5,  4000] loss: 0.241\n",
            "[5,  6000] loss: 0.253\n",
            "[5,  8000] loss: 0.260\n",
            "[5, 10000] loss: 0.263\n",
            "[5, 12000] loss: 0.242\n",
            "[5, 14000] loss: 0.252\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 92 %\n",
            "Training Model 6\n",
            "[1,  2000] loss: 0.944\n",
            "[1,  4000] loss: 0.585\n",
            "[1,  6000] loss: 0.520\n",
            "[1,  8000] loss: 0.465\n",
            "[1, 10000] loss: 0.453\n",
            "[1, 12000] loss: 0.424\n",
            "[1, 14000] loss: 0.411\n",
            "[2,  2000] loss: 0.380\n",
            "[2,  4000] loss: 0.386\n",
            "[2,  6000] loss: 0.363\n",
            "[2,  8000] loss: 0.372\n",
            "[2, 10000] loss: 0.367\n",
            "[2, 12000] loss: 0.358\n",
            "[2, 14000] loss: 0.364\n",
            "[3,  2000] loss: 0.336\n",
            "[3,  4000] loss: 0.341\n",
            "[3,  6000] loss: 0.336\n",
            "[3,  8000] loss: 0.337\n",
            "[3, 10000] loss: 0.328\n",
            "[3, 12000] loss: 0.307\n",
            "[3, 14000] loss: 0.316\n",
            "[4,  2000] loss: 0.299\n",
            "[4,  4000] loss: 0.308\n",
            "[4,  6000] loss: 0.310\n",
            "[4,  8000] loss: 0.314\n",
            "[4, 10000] loss: 0.308\n",
            "[4, 12000] loss: 0.325\n",
            "[4, 14000] loss: 0.293\n",
            "[5,  2000] loss: 0.287\n",
            "[5,  4000] loss: 0.283\n",
            "[5,  6000] loss: 0.297\n",
            "[5,  8000] loss: 0.296\n",
            "[5, 10000] loss: 0.277\n",
            "[5, 12000] loss: 0.296\n",
            "[5, 14000] loss: 0.293\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different configurations to try\n",
        "configurations = [\n",
        "    {'activation': 'ReLU', 'pooling': 'max', 'optimizer': 'sgd', 'lr': 0.01, 'dropout_prob': 0.5, 'augmentation': True},\n",
        "    {'activation': 'Sigmoid', 'pooling': 'max', 'optimizer': 'sgd', 'lr': 0.05, 'dropout_prob': 0.5, 'augmentation': True}\n",
        "]\n",
        "\n",
        "# Iterate over configurations and train models\n",
        "for idx, config in enumerate(configurations, start=1):\n",
        "    print(f\"Training Model {idx}\")\n",
        "\n",
        "    activation = config['activation']\n",
        "    pooling = config['pooling']\n",
        "    optimizer = config['optimizer']\n",
        "    lr = config['lr']\n",
        "    dropout_prob = config['dropout_prob']\n",
        "    augmentation = config['augmentation']\n",
        "\n",
        "    # Build the CNN model\n",
        "    model, optimizer = build_cnn(in_channels, hidden_layers, activation, pooling, optimizer, lr, dropout_prob)\n",
        "\n",
        "    # Data augmentation\n",
        "    if augmentation:\n",
        "        trainset_augmented = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True,\n",
        "                                                               transform=transforms.Compose([\n",
        "                                                                   transforms.RandomHorizontalFlip(),\n",
        "                                                                   transforms.RandomRotation(10),\n",
        "                                                                   transforms.ToTensor(),\n",
        "                                                                   transforms.Normalize((0.5,), (0.5,))\n",
        "                                                               ]))\n",
        "        trainloader_augmented = torch.utils.data.DataLoader(trainset_augmented, batch_size=4, shuffle=True, num_workers=2)\n",
        "        trainloader_used = trainloader_augmented\n",
        "    else:\n",
        "        trainloader_used = trainloader\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    test_accuracy = train_and_evaluate(model, optimizer, trainloader_used, trainloader, epochs)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vrpc7aydxWRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7daf03fd-3ccd-4fcd-b3d3-529115b42f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.039\n",
            "[1,  4000] loss: 0.679\n",
            "[1,  6000] loss: 0.600\n",
            "[1,  8000] loss: 0.541\n",
            "[1, 10000] loss: 0.530\n",
            "[1, 12000] loss: 0.501\n",
            "[1, 14000] loss: 0.482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,  2000] loss: 0.461\n",
            "[2,  4000] loss: 0.470\n",
            "[2,  6000] loss: 0.445\n",
            "[2,  8000] loss: 0.427\n",
            "[2, 10000] loss: 0.438\n",
            "[2, 12000] loss: 0.435\n",
            "[2, 14000] loss: 0.405\n",
            "[3,  2000] loss: 0.410\n",
            "[3,  4000] loss: 0.406\n",
            "[3,  6000] loss: 0.406\n",
            "[3,  8000] loss: 0.415\n",
            "[3, 10000] loss: 0.397\n",
            "[3, 12000] loss: 0.392\n",
            "[3, 14000] loss: 0.382\n",
            "[4,  2000] loss: 0.385\n",
            "[4,  4000] loss: 0.384\n",
            "[4,  6000] loss: 0.386\n",
            "[4,  8000] loss: 0.381\n",
            "[4, 10000] loss: 0.379\n",
            "[4, 12000] loss: 0.371\n",
            "[4, 14000] loss: 0.366\n",
            "[5,  2000] loss: 0.360\n",
            "[5,  4000] loss: 0.358\n",
            "[5,  6000] loss: 0.363\n",
            "[5,  8000] loss: 0.379\n",
            "[5, 10000] loss: 0.370\n",
            "[5, 12000] loss: 0.365\n",
            "[5, 14000] loss: 0.355\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Training Model 2\n",
            "[1,  2000] loss: 2.309\n",
            "[1,  4000] loss: 2.306\n",
            "[1,  6000] loss: 2.306\n",
            "[1,  8000] loss: 2.306\n",
            "[1, 10000] loss: 2.305\n",
            "[1, 12000] loss: 2.185\n",
            "[1, 14000] loss: 1.025\n",
            "[2,  2000] loss: 0.699\n",
            "[2,  4000] loss: 0.650\n",
            "[2,  6000] loss: 0.632\n",
            "[2,  8000] loss: 0.613\n",
            "[2, 10000] loss: 0.573\n",
            "[2, 12000] loss: 0.564\n",
            "[2, 14000] loss: 0.552\n",
            "[3,  2000] loss: 0.518\n",
            "[3,  4000] loss: 0.499\n",
            "[3,  6000] loss: 0.497\n",
            "[3,  8000] loss: 0.507\n",
            "[3, 10000] loss: 0.480\n",
            "[3, 12000] loss: 0.481\n",
            "[3, 14000] loss: 0.478\n",
            "[4,  2000] loss: 0.461\n",
            "[4,  4000] loss: 0.450\n",
            "[4,  6000] loss: 0.452\n",
            "[4,  8000] loss: 0.436\n",
            "[4, 10000] loss: 0.435\n",
            "[4, 12000] loss: 0.423\n",
            "[4, 14000] loss: 0.418\n",
            "[5,  2000] loss: 0.420\n",
            "[5,  4000] loss: 0.413\n",
            "[5,  6000] loss: 0.411\n",
            "[5,  8000] loss: 0.402\n",
            "[5, 10000] loss: 0.402\n",
            "[5, 12000] loss: 0.407\n",
            "[5, 14000] loss: 0.405\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 87 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQADpp3r252J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different configurations to try\n",
        "configurations = [\n",
        "\n",
        "    {'activation': 'Sigmoid', 'pooling': 'max', 'optimizer': 'sgd', 'lr': 0.05, 'dropout_prob': 0, 'augmentation': True}\n",
        "]\n",
        "\n",
        "# Iterate over configurations and train models\n",
        "for idx, config in enumerate(configurations, start=1):\n",
        "    print(f\"Training Model {idx}\")\n",
        "\n",
        "    activation = config['activation']\n",
        "    pooling = config['pooling']\n",
        "    optimizer = config['optimizer']\n",
        "    lr = config['lr']\n",
        "    dropout_prob = config['dropout_prob']\n",
        "    augmentation = config['augmentation']\n",
        "\n",
        "    # Build the CNN model\n",
        "    model, optimizer = build_cnn(in_channels, hidden_layers, activation, pooling, optimizer, lr, dropout_prob)\n",
        "\n",
        "    # Data augmentation\n",
        "    if augmentation:\n",
        "        trainset_augmented = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True,\n",
        "                                                               transform=transforms.Compose([\n",
        "                                                                   transforms.RandomHorizontalFlip(),\n",
        "                                                                   transforms.RandomRotation(10),\n",
        "                                                                   transforms.ToTensor(),\n",
        "                                                                   transforms.Normalize((0.5,), (0.5,))\n",
        "                                                               ]))\n",
        "        trainloader_augmented = torch.utils.data.DataLoader(trainset_augmented, batch_size=4, shuffle=True, num_workers=2)\n",
        "        trainloader_used = trainloader_augmented\n",
        "    else:\n",
        "        trainloader_used = trainloader\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    test_accuracy = train_and_evaluate(model, optimizer, trainloader_used, trainloader, 7)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecba4e3-4733-44a8-8985-d59e9c07afc0",
        "id": "uH-IjuvA7dXG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.309\n",
            "[1,  4000] loss: 2.305\n",
            "[1,  6000] loss: 2.306\n",
            "[1,  8000] loss: 2.305\n",
            "[1, 10000] loss: 2.305\n",
            "[1, 12000] loss: 1.678\n",
            "[1, 14000] loss: 0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,  2000] loss: 0.640\n",
            "[2,  4000] loss: 0.601\n",
            "[2,  6000] loss: 0.563\n",
            "[2,  8000] loss: 0.524\n",
            "[2, 10000] loss: 0.527\n",
            "[2, 12000] loss: 0.506\n",
            "[2, 14000] loss: 0.472\n",
            "[3,  2000] loss: 0.473\n",
            "[3,  4000] loss: 0.438\n",
            "[3,  6000] loss: 0.428\n",
            "[3,  8000] loss: 0.435\n",
            "[3, 10000] loss: 0.406\n",
            "[3, 12000] loss: 0.403\n",
            "[3, 14000] loss: 0.387\n",
            "[4,  2000] loss: 0.380\n",
            "[4,  4000] loss: 0.369\n",
            "[4,  6000] loss: 0.351\n",
            "[4,  8000] loss: 0.382\n",
            "[4, 10000] loss: 0.365\n",
            "[4, 12000] loss: 0.369\n",
            "[4, 14000] loss: 0.344\n",
            "[5,  2000] loss: 0.344\n",
            "[5,  4000] loss: 0.333\n",
            "[5,  6000] loss: 0.341\n",
            "[5,  8000] loss: 0.333\n",
            "[5, 10000] loss: 0.328\n",
            "[5, 12000] loss: 0.332\n",
            "[5, 14000] loss: 0.321\n",
            "[6,  2000] loss: 0.309\n",
            "[6,  4000] loss: 0.309\n",
            "[6,  6000] loss: 0.312\n",
            "[6,  8000] loss: 0.311\n",
            "[6, 10000] loss: 0.304\n",
            "[6, 12000] loss: 0.298\n",
            "[6, 14000] loss: 0.298\n",
            "[7,  2000] loss: 0.296\n",
            "[7,  4000] loss: 0.288\n",
            "[7,  6000] loss: 0.287\n",
            "[7,  8000] loss: 0.282\n",
            "[7, 10000] loss: 0.298\n",
            "[7, 12000] loss: 0.281\n",
            "[7, 14000] loss: 0.275\n",
            "Finished Training\n",
            "Accuracy of the network on the test images: 90 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Summary"
      ],
      "metadata": {
        "id": "C3jdZfLV-6xK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Activation | Optimizer | Pooling | LR   | Drop-out | Augmentation | Accuracy |\n",
        "|------------|-----------|---------|------|----------|--------------|----------|\n",
        "| Sigmoid    | Adam      | Max     | 0.001| 0.5      | ✅           | 88%      |\n",
        "| Tanh       | Adam      | Max     | 0.001| 0.5      | ❎           | 85%      |\n",
        "| ReLU       | Adam      | Avg     | 0.01 | 0        | ✅           | 10%      |\n",
        "| ReLU       | Adam      | Avg     | 0.01 | 0.5      | ❎           | 10%      |\n",
        "| <tr style=\"background-color:#D1E9A9\"><td>ReLU</td><td>SGD</td><td>Max</td><td>0.01</td><td>0</td><td>✅</td><td>92%</td></tr> |\n",
        "| ReLU       | SGD       | Max     | 0.01 | 0.5      | ✅           | 89%      |\n",
        "| Sigmoid    | SGD       | Max     | 0.05 | 0.5      | ✅           | 87%      |\n",
        "| Sigmoid    | SGD       | Max     | 0.05 | 0        | ✅           | 90%         |\n"
      ],
      "metadata": {
        "id": "nBzLx7jKDsc7"
      }
    }
  ]
}